---
layout: article
title: Part I. Machine Learning 
key: 0
tags: ml
category: ml concept
date: 2020-10-30 09:48:00 +08:00
revised-date: 2021-06-20 10:00:00
picture_frame: shadow

---

Part I. Machine Learning 


ⓒ [라온피플](https://blog.naver.com/laonple), Stanford cs231n, Stanford cs221, W. Kim 

**fly to the moon.**
<!--more-->

#  1. The Introduction to the Machine Learning

## 1.0. Intro

요새는 인공지능에 대한 소식을 접하지 않는 것이 어려울 정도로 인공지능은 호황이다. Jeopardy! (IBM Watson, 2011), Go (DeepMind’s AlphaGo, 2016), Dota 2 (OpenAI, 2019), Poker (CMU and Facebook, 2019)

그러나 미래에 무슨 결과를 가져올지 아무도 모른다. 인류의 종말을 야기할지, 산업혁명과 같이 엄청난 효과를 가져올지, 인간 수준을 넘어서 지배력을 추구할지.

## 1.1. Machine Learning의 정의

1959년 Arthur Samuel은 기계 학습에 대해서 다음과 같이 정의를 했다.

>  “Field of study that gives computers the ability to learn without being explicitly programmed”.
>
> 이런 경우에는 이렇게 동작하고, 저런 경우에는 저렇게 동작하라는 등, 가능한 모든 경우의 수를 프로그래머가 정의해주지 않더라도, 데이터를 통한 학습을 하여 최적의 판단이나 예측을 가능하게 해주는 것을 말한다.

- 가령 필기체를 인식하는 프로그램을 개발한다고 가정을 해보자. 
  - 사람들이 매우 다양한 방법으로 손글씨를 쓰기 때문에, 손글씨 영상에 대해 평균화 작업 및 기타 전처리 작업을 하더라도, 프로그래머가 사전에 모든 경우의 수를 프로그램 해준다는 것은 사실상 불가능하다. 이런 경우에 기계 학습이 개념이 필요해진다. 마치 사람들이 의식적인 혹은 무의식적인 학습을 통해 판단/구별/인지 하는 것을 배우듯이, 적절한 기계 학습법을 통해 사람의 직접적인 개입 없이, 글자를 인식하거나, 음성을 인식하는 것들이 가능해진다.


## 1.2. Machine Learning의 분류

- 이런 기계학습은 data mining 또는 패턴 인식이라고도 불린다. 기계 학습은 크게 **지도학습(supervised learning)과 자율학습(unsupervised learning, 비지도 학습**)으로 분류를 하고 있다. 하지만 경우에 따라 **강화 학습(reinforcement learning)**을 추가하여 3가지로 분류를 하는 사람들도 있다.
- **지도 학습(supervised learning)**
  - Given Data, Label을 활용해 미지의 상태나 값을 예측하는 학습 방법
  - 어떤 입력에 대해서 어떤 결과가 나와야 하는지 사전 지식을 갖고 있는 경우에 해당 입력에 대해 특정 출력(label)이 나오도록 하는 규칙을 찾아낸다. 보통은 입력과 출력 쌍으로 구성되는 학습 데이터(training data)에 의해 입력으로부터 출력을 끌어내는 규칙(rule)을 발견하는 것을 학습의 목표로 하며, 흔히 말하는 회귀(regression) 방법이 여기에 해당한다. 현재까지 가장 많이, 그리고 활발하게 연구가 진행된 분야로 우리가 알고 있는 많은 학습 방법이 여기에 해당 된다.
  - 예 : 내일의 주식 시장 예전 시장상황 변화 양상 보고 예측하기, 해당 문서의 카테고리 단어 보고 분류하기 등
- **비지도 학습(unsupervised learning)**
  - Given Data, Label 간 연관 관계를 구하는 것이 아닌, 데이터 자체에서의 유용한 패턴 파악하는 학습 방법
  - 입력은 있지만 정해진 출력이 없는 경우를 말하며, 순수하게 데이터들이 갖고 있는 속성들을 이용해 그룹으로 나누는 경우를 말하며, 지도학습이 회귀 방법을 사용하는 것과 달리, 분류(clustering)에 해당이 된다. 가령 사람들이 나이, 학력, 성별, 출생 지역 등의 조합에 따라 어떤 정당을 지지하는지 살펴보는 것도 자율 학습에 속한다. 일반적으로는 시장 조사, 컴퓨터 클러스터링, 그림이나 동영상에 대한 auto-tagging 등에 사용이 된다.
  - 데이터의 성질을 직접적으로 추측한다는 점에서 Supervised와 차이를 갖는다.
- **강화 학습(reinforcement learning)**
  - 기계(Agent) 가 환경과의 상호작용 (Choice & Feedback의 Iteration)으로 장기적인 이득을 최대화하는 학습 방법
  - 로봇의 학습 등에 사용할 수 있으며, 자신과 환경과의 상호 관계에 따라 자신의 행동을 개선해 나가는 학습법을 말한다. 가령 칭찬을 받은 행위는 더욱 많이 하고, 벌을 받을만한 행위는 줄이는 것과 마찬가지로 적응성을 통해 학습을 강화해가는 것을 말한다. 물론 학습의 결과가 즉각적으로 나타나는 경우에 효과적이라고 할 수 있다.
  - Exploitation : 현재 가진 정보로 다음 Action 정하기
  - Exploration : 새로운 정보를 얻기 위해 가보지 않은 곳 가기

## 1.3. Machine Learning의 3가지 관점

![image](https://user-images.githubusercontent.com/46957634/122716445-38d74180-d2a5-11eb-9419-4aef7292099d.png)

![image](https://user-images.githubusercontent.com/46957634/122716721-95d2f780-d2a5-11eb-9746-0bb9763e5902.png)

- [사진1] [The Three Cultures of Machine Learning by Jason Eisner (2015)](https://www.cs.jhu.edu/~jason/tutorials/ml-simplex.html)
- [사진2] [R. A. Fisher in the 21st century (Invited paper presented at the 1996 R. A. Fisher Lecture)](https://projecteuclid.org/journals/statistical-science/volume-13/issue-2/R-A-Fisher-in-the-21st-century-Invited-paper-presented/10.1214/ss/1028905930.full)
- Frequentist : 확률을 객관적으로 발생하는 현상의 빈도수에 대한 기술로 보느냐 
- Bayesian : 현상에 대한 관찰자의 주관적인 믿음의 체계로 보느냐

## 2. Supervised Learning

### 2.1. 지도 학습(Supervised Learning) 개요

- Supervisor를 사전에서 찾아보면 작업 현장을 지휘 통제하는 ‘감독관’, 학생을 가르치고 인도하는 ‘지도교수’ 등의 의미를 갖고 있다.

그러므로 지도 학습이란 이미 주어진 입력에 대해 어떤 결과가 나올지 알고 있는, 전문 용어로는 labeling이 된, 출력과의 관계를 이용해서 데이터 들을 해석할 수 있는 모델을 만들고,
그것을 바탕으로 새로운 데이터를 추정(predict)하는 것을 말한다. 즉, 과거의 지식을 이용해 미래를 예측하는 것과 마찬가지 이다.
좋은 학습 결과를 얻으려면, 일반적으로 훈련 데이터(training data)의 양이 많아야 하며, 훈련 데이터가 범용성을(generalization) 갖고 있어야 한다.

### 2.2. 지도 학습(Supervised Learning) 단계

지도학습은 다음 단계를 거친다

1. 학습에 사용할 훈련 데이터를 정한다. 훈련 데이터는 모델의 성패 여부를 결정하기 때문에 잘 선정을 해야 한다.
2. 훈련 데이터를 모은다.
3. 입력의 특징(feature)을 어떻게 표현할 것인지 결정한다. 일반적으로는 벡터 형태로 표현을 한다. 차원의 저주(curse of dimensionality)에 빠지지 않도록 특징의 수를 너무 크게 해서는 안된다.
4. 학습 알고리즘을 결정한다.
   지도 학습 방법을 사용할 알고리즘이 매우 많고 그 특성도 다양하기 때문에
    적용할 분야에 맞춰 적절한 알고리즘을 선택해야 한다.
5. 훈련 데이터를 이용해 학습 알고리즘을 실행한다.
6. 만들어진 모델의 정확도를 평가한다. 보통은 훈련 데이터와 다른 테스트 데이터를 이용해 이 과정을 수행한다.

### 2.3. 지도 학습(Supervised Learning) 알고리즘

- 1. Regression
     - 대개 숫자 값 예측
  2. Classification
     - 주어진 항복들로 입력 데이터들을 나누는 방법
     - [paperswithcode](https://paperswithcode.com/task/image-classification)
  3. Ranking / Recommendation
     - 상품에 대한 사용자 선호도를 예측하는 시스템
     - [사진] A curated list of awesome Recommender System - designed by **Jihoo Kim** [link](https://github.com/jihoo-kim/awesome-RecSys)
     - ![RS](https://user-images.githubusercontent.com/50820635/85274861-7e0e3b00-b4ba-11ea-8cd3-2690ec55a67a.jpg)
- 대표적인 지도 학습 알고리즘의 종류는 다음과 같다.
  - Artificial neural network
  - Boosting
  - Bayesian statistics
  - Decision tree
  - Gaussian process regression
  - Nearest neighbor algorithm
  - Support vector machine
  - Random forests
  - Symbolic machine learning
  - Ensembles of classifiers


## 3. Unsupervised Learning 

### 3.1.  지도학습과의 차이점

##### - Supervised Learning(지도 학습)과 Unsupervised Learning(자율 학습, 비지도 학습)  

- 기계학습을 연구하는 사람들의 꿈은 데이터만 넣어주면 모든 것을 알아서 척척 처리해주는 시스템일 것이다. 하지만, 앞서 살펴본 것처럼 지도 학습을 통해 특정 입력을 가했을 때 어떤 출력을 내줘야 한다는 것은 이미 알고 있는 시스템에서도 요원한 일이다. 이것은 학교에서 선생님이 친절하게 가르쳐주더라도 시험에서 모든 사람이 만점을 받을 확률이 거의 없는 것과 마찬가지이다. 자율 학습이란 그런 선생님의 지도 없이도 만점을 받기를 기대하는 것과 같기 때문에, 훨씬 더 어렵다고 볼 수 있다.

- 지도 학습의 경우는 훈련(training)을 통해 error function 혹은 loss function을 구할 수 있으며, 이 값을 피드백(훈련 결과의 양호함을 판단)으로 활용하여 모델을 개선 시킬 수 있으나, 자율 학습의 경우는 이렇게 이용할 수 있는 수단이 없다는 점에서 다르다. 어찌 보면, 통계에서 밀도를 추정하는 것과 비슷하다.

- 기계 학습의 종류 중 하나인 ‘강화 학습 (reinforcement learning)’의 경우는 지도 학습의 경우처럼, 사전에 기대하는 결과가 있는 것은 아니지만, 동작 하는 환경과의 상호 작용을 통해, 그 결과로서 보상(reward) 혹은 벌(punishment)을 받기 때문에 어떤 의미에서 보면 자율 학습에 비해 쉽다고(?) 할 수도 있다.

### 3.2. Unsupervised Learning (자율 학습, 비지도 학습) 개요

- 기대할 수 있는 올바른 답도 없고, 결과로서의 보상 또는 벌도 없다면, 도대체 어떻게 학습을 수행할 수 있을까?
- 하지만, 결론부터 말하면 학습이 가능하다.
  - 기계 학습의 목표가 입력들이 주어졌을 경우 그 입력에 대한 결정을 하고(decision making),
    새로운 입력이 들어올 경우 결과를 예측하는(predicting future input) 모델(representation)을 만드는 것이기 때문에, 이것을 가능하게 하는 프레임워크를 만들 수 있다.
- 초기 신경망 회로(neural network)는 지도 학습을 이용해, 인쇄된 문자 인식, 필기체 인식 및 음성 인식에서 탁월한 효과를 보였다.
- 최근은 SOM(Self-Organizing Map)과 ART(Adaptive Resonance Theory)와 같은 자율 학습(Unsupervised learning)을 이용한 응용 연구가 활발히 진행이 되고 있다.

### 3.3. Unsupervised Learning) 알고리즘

- 1. Clustering / Topic Modeling

     - 비슷한 데이터를 묶어 큰 단위로 만드는 기법

  2. Density Estimation

     - 관측 데이터로부터 데이터를 생성한 원래 분포 추정하는 방법

  3. Dimension Reduction

     - 주로 데이터가 높고 복잡한 차원을 가져 시각화하기 어려울 때 저차원으로 표현하기 위해 사용
     - PCA(Principle Component Analysis)
     - ICA(Independent Component Analysis)
     - Non-negative matrix factorization 및 SVD(Singlular Value Decomposition) 

     


## 4. Reinforcement Learning (강화 학습)

### 4.1. Reinforcement Learning(강화 학습)개요

Reinforcement를 사전에서 찾아보면, 군대나 경찰 등의 ‘증원 요원’ 또는 감정이나 생각 등의 ‘강화’라는 뜻으로 사용됨을 알 수 있다. 기계 학습(machine learning)의 방법 중 하나로 reinforcement learning이라는 개념이 사용될 때, 우리말로는 대부분 ‘강화 학습’이라는 말로 번역이 된다.


왜 학습에 ‘강화’라는 말이 붙게 되었을까?


이것을 설명하기 전에 개를 훈련시키는 것을 상상해보면 이해가 쉽다. 보통 개를 훈련시키는 경우 개가 훈련을 잘 따르면 ‘상(reward)’을 주고, 잘 따르지 못하면 ‘벌(punishment)’을 준다.

는 상과 벌을 통해 훈련자가 원하는 방향으로 학습을 하게 된다.
여기서 훈련에 잘 따른다는 것은 지도 학습(supervised learning)의 경우처럼, 명확한 관계 (즉, 오직 한가지 결과)만 기대할 수 있는 것이 아니라, ‘잘 했다’라는 것은 여러 가지 상황이 있다는 점에 주목해야 한다.

### 4.2. Reinforcement Learnin(강화 학습)의 적용


강화라는 말을 사용한 이유는 상과 벌이라는 보상을 통해 ‘현재의 행위의 그 방향’으로 혹은 ‘반대방향’으로 그 행위를 강화하는 학습 방법으로, 상을 최대한 많이 받을 수 있는 방향으로 학습하는 방법이며, 로봇이나 인공지능 분야에서 많이 사용된다.


지도 학습의 경우처럼, 입력과 출력이 명확한 관계를 갖고 있는 상황이 아니라, 환경과의 상호 작용의 결과로서 학습을 하거나, 훈련 모델을 사전에 명확하게 기술하기 어려운 경우에 적용할 수 있는 학습 방법이다. 강화 학습은 보상을 최대화시키기 위해 무엇을 할 것인가를 배우는 것이다. 학습자는 지도 학습의 경우처럼 사전에 어떤 행위를 하지 할 것인지 듣고 하는 것이 아니라, 시행착오를 거치면서 보상을 최대화시키는 것을 배우는 것이다. 흥미로운 사실은, 어떤 행위에 대한 보상뿐만 아니라, 다음 상황 및 그것의 결과로서의 보상에 영향을 받게 된다는 점이다. ‘시행착오를 통한 탐색 혹은 결정(decision making through trial-and-error)’ 및 ‘지연 보상(delayed reward)’은 강화학습을 다른 학습과 구별하게 만드는 두 가지 특징이다.


강화 학습(줄여서, RL이라는 말을 많이 사용함)의 표준 프레임워크에서는 학습자(가령, 동물이나 로봇)는 반복적으로 환경의 상태를 주시하면서, 어떤 행위를 할 것인지를 선택한다. 학습자는 상(reward)을 최대화 시키기 위해, 결과를 수치적으로 파악할 수 있어야 하며, 장시간 동안의 합을 최대화시키는 방향 혹은 미래에 받을 상의 평균을 최대화 시키는 방향으로 학습을 배우게 된다.


강화 학습은 game theory, control theory, simulation-based optimization, multi-agent systems, genetic algorithms, 및 operation research 등 다양한 분야에서 활발하게 연구가 되고 있다.

## 5. Deep Learning

### 5.1. Deep Learning 개요

![심층 학습 및 기계 학습 - Azure Machine Learning | Microsoft Docs](https://docs.microsoft.com/ko-kr/azure/machine-learning/media/concept-deep-learning-vs-machine-learning/ai-vs-machine-learning-vs-deep-learning.png)

- 수많은 데이터의 양과 엄청난 양의 계산이 필요하기 때문에 딥 러닝의 상용화는 처음부터 어려움에 직면했다. 그럼에도 불구하고, 토론토 대학의 Geoffrey Hinton 연구팀과 같은 일부 기관들은 연구를 계속하여 슈퍼컴퓨터를 기반으로 딥 러닝 개념을 증명하는 알고리듬의 병렬화에 성공했다. 그리고 병렬 운영을 위해 최적화된 GPU의 등장은 신경망의 계산 속도를 극적으로 가속화하여 진정한 딥 러닝 기반 인공지능의 출현으로 이어졌다.
- Differences with Machine Learning
  - Deep learning : learn itself 
  - Machine learning : learn by someone

## 6. Approaching AI

### 6.1. The Melting Pot

- Bayes rule (Bayes, 1763) from probability  
- Least squares regression (Gauss, 1795) from astronomy 
- First-order logic (Frege, 1893) from logic 
- Maximum likelihood (Fisher, 1922) from statistics 
- Artificial neural networks (McCulloch/Pitts, 1943) from neuroscience 
- Minimax games (von Neumann, 1944) from economics 
- Stochastic gradient descent (Robbins/Monro, 1951) from optimization 
- Uniform cost search (Dijkstra, 1956) from algorithms 
- Value iteration (Bellman, 1957) from control theory

마치 인공지능은 U.S.의 [Melting Pot](https://en.wikipedia.org/wiki/Melting_pot) 이라 불리는 New York City처럼, 현대 사회의 통계학, 논리학, 경제학, 알고리즘 등 다양한 분야에서 이끌어져 왔다. 종종 이러한 분야와 실제 현안에 대한 새로운 연결로 인해 AI 직무에서 일한다는 건 때론 Rewarding하게도 느껴진다.

### 6.2. Philosophical Approach

- (1) normally associate with AI: the science and engineering of building ”intelligent” agents.
  - 지성을 구성하는 것의 영감은 인간이 가지고 있는 능력의 종류로부터 온다. 매우 복잡한 세계를 인지하고 그것을 조종할 수 있을 만큼 충분히 이해할 수 있는 능력이다. 
- (2) views AI as a set of tools 두 번째는 AI를 도구 집합으로 본다. 
  - 우리는 단순히 세계의 문제를 해결하기 위해 노력하고 있고, AI 커뮤니티가 개발한 기술들이 그것에 유용하게 쓰이기는 하지만, 이러한 문제들이 인간이 반드시 선천적으로 잘하는 것은 아니다.
- 그러나 두 가지 견해는 모두 동일한 일상 활동(예: 데이터 수집 및 훈련 목표 최적화)의 많은 것으로 요약된다. 철학적 차이는 AI 연구자들이 작업에 접근하고 이야기하는 방식을 변화시킨다. 게다가, 이 두 관점의 충돌은 많은 혼란을 일으킬 수 있다.

#### 6.2.1. AI Agent

- Starting point of agent-based view : **Ourselves**
  - Computer Vision : 인간으로서 우리는 세상을 지각할 수 있어야 하고
  - Robotics : 그 안에서 행동을 수행할 수 있어야 하며
  - Language : 다른 Agent 와 Communication 할 수 있어야 하며
  - Knowledge : 
    - from procedural knowledge like how to ride a bike, 
    - to declarative knowledge like remembering the capital of France
  - Reasoning
    - 이러한 지식을 활용하여 추론을 도출하고 의사결정을 내릴 수 있다
- 우리는 시간이 지남에 따라 배우고 적응합니다. 우리는 성인이 되어 가지고 있는 어떤 기술도 가지고 있지 않고 오히려 그것을 습득할 수 있는 능력을 가지고 태어난다. 실제로 머신 러닝은 오늘날 우리가 보는 많은 AI 응용 프로그램의 Primary Driver가 되었다.
- 아직 갈 길은 멀다. 1,960만 게임으로부터 학습한 AlphaGo 이지만 인간과 달리 오직 바둑 하나만 할 수 있다. 반면에 인간은 훨씬 더 광범위한 경험으로부터 배우고 많은 것을 할 수 있다.

#### 6.2.2. AI Tools

- 인간이 가진 능력을 다시 창조하는 것이 아니라 인간에게 이익을 주는 방법에 관한 것이다.
- 이미 실무에서 광범위하게 구현되고 있으며, 이러한 설정 중 많은 부분이 특별히 인간과 유사한 경우가 많다
- 예 : targeted advertising, news or product recommendation, web search, supply chain management, etc.

## 7. Exploition

### 7.1. Papers

- [The interaction of nature and nurture in development: A parallel distributed processing perspective](https://psycnet.apa.org/record/1994-98068-004)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
  - [transformers are graph neural networks](https://graphdeeplearning.github.io/post/transformers-are-gnns/)
- [Deep contextualized word representations](https://arxiv.org/abs/1802.05365) (ELMo) 
  - LSTM
- [GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](https://arxiv.org/abs/1804.07461)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
- [Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/1911.05722) (MoCo)
- [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709) (SimCLR)  
- [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872), 
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
  - ViT
- Transfer Learning at NLP
  - [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)
  - [pretrained weight](https://huggingface.co/transformers/model_doc/t5.html), [라이브러리 코드](https://github.com/huggingface/transformers)

- Graph
  - [GNN 소개 — 기초부터 논문까지](https://medium.com/watcha/gnn-%EC%86%8C%EA%B0%9C-%EA%B8%B0%EC%B4%88%EB%B6%80%ED%84%B0-%EB%85%BC%EB%AC%B8%EA%B9%8C%EC%A7%80-96567b783479)
  - [Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, Philip S. Yu, “A Comprehensive Survey on Graph Neural Networks”](https://arxiv.org/abs/1901.00596)
- XAI
  - [Towards Better Analysis of Deep Convolutional Neural Networks](https://ieeexplore.ieee.org/abstract/document/7536654)
  - [Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey](https://arxiv.org/abs/2006.11371)
- Optimal Transport
  - [Computational Optimal Transport](https://arxiv.org/abs/1803.00567)
- DML
  - [Improving Multilingual Sentence Embedding using Bi-directional Dual Encoder with Additive Margin Softmax](https://arxiv.org/abs/1902.08564) 
  - [Additive margin softmax for face verification](https://arxiv.org/abs/1801.05599)
- Time Series
  -  [Neural Ordinary Differential Equations](https://arxiv.org/abs/1806.07366)
  - [Dissecting Neural ODEs](https://arxiv.org/abs/2002.08071)
  - [Latent ODEs for Irregularly-Sampled Time Series](
